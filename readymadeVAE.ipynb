{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 785)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.MnistDataset at 0x7f0708a08a58>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "class MnistDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, file, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        data = pd.read_csv(file)\n",
    "        print(data.shape)\n",
    "        self.x = data[data.columns[1:]].values.view(-1, 28,28) / 255\n",
    "        self.y = data[data.columns[0]].values\n",
    "        del data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx].reshape(1,28,28).astype(np.float32), self.y[idx]\n",
    "\n",
    "mnist_dataset = MnistDataset(\"../../239_all/239/6.Intro_to_NN/data/train.csv\")\n",
    "\n",
    "mnist_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(mnist_dataset, batch_size=4,\n",
    "                        shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class readymadeVAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(readymadeVAE, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(784, 400)\n",
    "        self.fc21 = nn.Linear(400, 10)\n",
    "        self.fc22 = nn.Linear(400, 10)\n",
    "        self.fc3 = nn.Linear(10, 400)\n",
    "        self.fc4 = nn.Linear(400, 784)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return eps.mul(std).add_(mu)\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        return torch.sigmoid(self.fc4(h3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x.view(-1, 784))\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"./models/encoder\")\n",
    "\n",
    "from models.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VAE([322], [322])\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "r_model = readymadeVAE()\n",
    "r_optimizer = optim.Adam(r_model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 28, 28])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.4565, 0.5269, 0.4947,  ..., 0.4720, 0.5941, 0.4858],\n",
       "         [0.4319, 0.5516, 0.4399,  ..., 0.5008, 0.4966, 0.5328],\n",
       "         [0.5095, 0.4770, 0.3752,  ..., 0.4886, 0.6522, 0.4138],\n",
       "         [0.4981, 0.5265, 0.4496,  ..., 0.4268, 0.5477, 0.5737]],\n",
       "        grad_fn=<SigmoidBackward>),\n",
       " tensor([[ 0.0523,  0.0963, -0.1258,  0.1204, -0.0472,  0.1281,  0.0230,  0.1104,\n",
       "          -0.1819, -0.0618],\n",
       "         [-0.0204,  0.0783, -0.1201,  0.0427, -0.1156,  0.2701,  0.0294,  0.2823,\n",
       "          -0.1711, -0.1099],\n",
       "         [ 0.0273,  0.0319, -0.0960,  0.0877, -0.0300,  0.1297,  0.0942,  0.0984,\n",
       "          -0.0943, -0.1065],\n",
       "         [-0.0149, -0.0522, -0.1054,  0.0166, -0.0424,  0.1471,  0.0923,  0.1523,\n",
       "          -0.1665, -0.1135]], grad_fn=<ThAddmmBackward>),\n",
       " tensor([[-0.1003, -0.0254,  0.0532,  0.1187,  0.0890, -0.0329,  0.1429, -0.0515,\n",
       "           0.0292,  0.0931],\n",
       "         [ 0.0047, -0.0218,  0.2612,  0.1665, -0.1220, -0.0344,  0.1753, -0.0816,\n",
       "           0.1018,  0.1001],\n",
       "         [ 0.0060,  0.0589,  0.0469, -0.0408,  0.0049, -0.0731,  0.0804,  0.1073,\n",
       "           0.0109, -0.1241],\n",
       "         [ 0.0226,  0.0536,  0.0832, -0.0090,  0.0540,  0.0267,  0.0560,  0.1015,\n",
       "          -0.1006, -0.0291]], grad_fn=<ThAddmmBackward>))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(data.view(-1, 784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.4893, 0.4223, 0.4840,  ..., 0.5303, 0.5503, 0.5290],\n",
       "         [0.5316, 0.4284, 0.5506,  ..., 0.5401, 0.4504, 0.5455],\n",
       "         [0.4494, 0.4522, 0.4068,  ..., 0.5271, 0.4361, 0.5828],\n",
       "         [0.5606, 0.4432, 0.5079,  ..., 0.6242, 0.4571, 0.6160]],\n",
       "        grad_fn=<SigmoidBackward>),\n",
       " tensor([[ 0.1287,  0.0771, -0.0390,  0.0187, -0.0038, -0.0049,  0.0612, -0.0530,\n",
       "           0.0396,  0.1416],\n",
       "         [ 0.0854,  0.0871,  0.0792,  0.0239, -0.0575,  0.0082,  0.1015,  0.1042,\n",
       "           0.1251,  0.0799],\n",
       "         [-0.0209,  0.0221, -0.0213, -0.0351, -0.0681, -0.0401,  0.0341, -0.0330,\n",
       "           0.0153,  0.0219],\n",
       "         [ 0.0224,  0.0140,  0.0526, -0.0210, -0.0275,  0.0064,  0.0350,  0.0170,\n",
       "          -0.0295,  0.0472]], grad_fn=<ThAddmmBackward>),\n",
       " tensor([[ 0.1313,  0.0806, -0.1507, -0.0675,  0.0720,  0.0539,  0.0268, -0.0721,\n",
       "           0.0158, -0.1204],\n",
       "         [ 0.0593,  0.1292, -0.0468, -0.0725,  0.2111,  0.0588, -0.0295, -0.0054,\n",
       "          -0.0487, -0.2285],\n",
       "         [ 0.0984,  0.0543, -0.0541,  0.0424, -0.0380,  0.0497, -0.0220, -0.0797,\n",
       "           0.0125, -0.0349],\n",
       "         [ 0.0614,  0.0486, -0.0639,  0.0626, -0.0114,  0.0297, -0.0040, -0.0372,\n",
       "          -0.0685,  0.0425]], grad_fn=<ThAddmmBackward>))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([400, 784]) True\n",
      "torch.Size([400]) True\n",
      "torch.Size([10, 400]) True\n",
      "torch.Size([10]) True\n",
      "torch.Size([10, 400]) True\n",
      "torch.Size([10]) True\n",
      "torch.Size([400, 10]) True\n",
      "torch.Size([400]) True\n",
      "torch.Size([784, 400]) True\n",
      "torch.Size([784]) True\n"
     ]
    }
   ],
   "source": [
    "for p in model.parameters():\n",
    "    print(p.shape, p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.Size([400, 784]) True\n",
    "torch.Size([400]) True\n",
    "torch.Size([10, 400]) True\n",
    "torch.Size([10]) True\n",
    "torch.Size([10, 400]) True\n",
    "torch.Size([10]) True\n",
    "torch.Size([400, 10]) True\n",
    "torch.Size([400]) True\n",
    "torch.Size([784, 400]) True\n",
    "torch.Size([784]) True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruction + KL divergence losses summed over all elements and batch\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    BCE = F.binary_cross_entropy(recon_x, x.view(-1, 784), reduction='sum')\n",
    "\n",
    "    # see Appendix B from VAE paper:\n",
    "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
    "    # https://arxiv.org/abs/1312.6114\n",
    "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "\n",
    "    return BCE + KLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/42000 (0%)]\tLoss: 550.065125\n",
      "Train Epoch: 1 [400/42000 (1%)]\tLoss: 184.998627\n",
      "Train Epoch: 1 [800/42000 (2%)]\tLoss: 175.157623\n",
      "Train Epoch: 1 [1200/42000 (3%)]\tLoss: 151.511917\n",
      "Train Epoch: 1 [1600/42000 (4%)]\tLoss: 130.894669\n",
      "Train Epoch: 1 [2000/42000 (5%)]\tLoss: 210.291748\n",
      "Train Epoch: 1 [2400/42000 (6%)]\tLoss: 146.772766\n",
      "Train Epoch: 1 [2800/42000 (7%)]\tLoss: 144.213715\n",
      "Train Epoch: 1 [3200/42000 (8%)]\tLoss: 126.045113\n",
      "Train Epoch: 1 [3600/42000 (9%)]\tLoss: 135.661346\n",
      "Train Epoch: 1 [4000/42000 (10%)]\tLoss: 154.822189\n",
      "Train Epoch: 1 [4400/42000 (10%)]\tLoss: 141.933975\n",
      "Train Epoch: 1 [4800/42000 (11%)]\tLoss: 162.077301\n",
      "Train Epoch: 1 [5200/42000 (12%)]\tLoss: 98.855286\n",
      "Train Epoch: 1 [5600/42000 (13%)]\tLoss: 147.887039\n",
      "Train Epoch: 1 [6000/42000 (14%)]\tLoss: 141.169830\n",
      "Train Epoch: 1 [6400/42000 (15%)]\tLoss: 151.641953\n",
      "Train Epoch: 1 [6800/42000 (16%)]\tLoss: 113.113228\n",
      "Train Epoch: 1 [7200/42000 (17%)]\tLoss: 152.813004\n",
      "Train Epoch: 1 [7600/42000 (18%)]\tLoss: 131.998566\n",
      "Train Epoch: 1 [8000/42000 (19%)]\tLoss: 133.188446\n",
      "Train Epoch: 1 [8400/42000 (20%)]\tLoss: 141.694351\n",
      "Train Epoch: 1 [8800/42000 (21%)]\tLoss: 145.577393\n",
      "Train Epoch: 1 [9200/42000 (22%)]\tLoss: 140.418488\n",
      "Train Epoch: 1 [9600/42000 (23%)]\tLoss: 147.653168\n",
      "Train Epoch: 1 [10000/42000 (24%)]\tLoss: 120.830734\n",
      "Train Epoch: 1 [10400/42000 (25%)]\tLoss: 159.038055\n",
      "Train Epoch: 1 [10800/42000 (26%)]\tLoss: 126.643143\n",
      "Train Epoch: 1 [11200/42000 (27%)]\tLoss: 123.938202\n",
      "Train Epoch: 1 [11600/42000 (28%)]\tLoss: 134.925201\n",
      "Train Epoch: 1 [12000/42000 (29%)]\tLoss: 116.412437\n",
      "Train Epoch: 1 [12400/42000 (30%)]\tLoss: 162.642319\n",
      "Train Epoch: 1 [12800/42000 (30%)]\tLoss: 165.088593\n",
      "Train Epoch: 1 [13200/42000 (31%)]\tLoss: 144.977570\n",
      "Train Epoch: 1 [13600/42000 (32%)]\tLoss: 143.475433\n",
      "Train Epoch: 1 [14000/42000 (33%)]\tLoss: 164.487274\n",
      "Train Epoch: 1 [14400/42000 (34%)]\tLoss: 134.479065\n",
      "Train Epoch: 1 [14800/42000 (35%)]\tLoss: 161.370453\n",
      "Train Epoch: 1 [15200/42000 (36%)]\tLoss: 125.652130\n",
      "Train Epoch: 1 [15600/42000 (37%)]\tLoss: 94.079666\n",
      "Train Epoch: 1 [16000/42000 (38%)]\tLoss: 128.600220\n",
      "Train Epoch: 1 [16400/42000 (39%)]\tLoss: 144.539093\n",
      "Train Epoch: 1 [16800/42000 (40%)]\tLoss: 139.371521\n",
      "Train Epoch: 1 [17200/42000 (41%)]\tLoss: 104.865097\n",
      "Train Epoch: 1 [17600/42000 (42%)]\tLoss: 142.310181\n",
      "Train Epoch: 1 [18000/42000 (43%)]\tLoss: 140.637589\n",
      "Train Epoch: 1 [18400/42000 (44%)]\tLoss: 147.231400\n",
      "Train Epoch: 1 [18800/42000 (45%)]\tLoss: 151.240891\n",
      "Train Epoch: 1 [19200/42000 (46%)]\tLoss: 109.301346\n",
      "Train Epoch: 1 [19600/42000 (47%)]\tLoss: 114.875015\n",
      "Train Epoch: 1 [20000/42000 (48%)]\tLoss: 113.984039\n",
      "Train Epoch: 1 [20400/42000 (49%)]\tLoss: 131.902573\n",
      "Train Epoch: 1 [20800/42000 (50%)]\tLoss: 107.777916\n",
      "Train Epoch: 1 [21200/42000 (50%)]\tLoss: 151.607681\n",
      "Train Epoch: 1 [21600/42000 (51%)]\tLoss: 128.680420\n",
      "Train Epoch: 1 [22000/42000 (52%)]\tLoss: 149.214111\n",
      "Train Epoch: 1 [22400/42000 (53%)]\tLoss: 108.153458\n",
      "Train Epoch: 1 [22800/42000 (54%)]\tLoss: 100.652626\n",
      "Train Epoch: 1 [23200/42000 (55%)]\tLoss: 136.434265\n",
      "Train Epoch: 1 [23600/42000 (56%)]\tLoss: 123.853500\n",
      "Train Epoch: 1 [24000/42000 (57%)]\tLoss: 72.750931\n",
      "Train Epoch: 1 [24400/42000 (58%)]\tLoss: 112.193008\n",
      "Train Epoch: 1 [24800/42000 (59%)]\tLoss: 115.423218\n",
      "Train Epoch: 1 [25200/42000 (60%)]\tLoss: 142.947540\n",
      "Train Epoch: 1 [25600/42000 (61%)]\tLoss: 121.917297\n",
      "Train Epoch: 1 [26000/42000 (62%)]\tLoss: 126.403748\n",
      "Train Epoch: 1 [26400/42000 (63%)]\tLoss: 143.435181\n",
      "Train Epoch: 1 [26800/42000 (64%)]\tLoss: 147.880920\n",
      "Train Epoch: 1 [27200/42000 (65%)]\tLoss: 116.896042\n",
      "Train Epoch: 1 [27600/42000 (66%)]\tLoss: 115.351990\n",
      "Train Epoch: 1 [28000/42000 (67%)]\tLoss: 105.157333\n",
      "Train Epoch: 1 [28400/42000 (68%)]\tLoss: 98.563873\n",
      "Train Epoch: 1 [28800/42000 (69%)]\tLoss: 99.940208\n",
      "Train Epoch: 1 [29200/42000 (70%)]\tLoss: 122.422928\n",
      "Train Epoch: 1 [29600/42000 (70%)]\tLoss: 95.828232\n",
      "Train Epoch: 1 [30000/42000 (71%)]\tLoss: 110.908363\n",
      "Train Epoch: 1 [30400/42000 (72%)]\tLoss: 135.918716\n",
      "Train Epoch: 1 [30800/42000 (73%)]\tLoss: 124.050369\n",
      "Train Epoch: 1 [31200/42000 (74%)]\tLoss: 131.531616\n",
      "Train Epoch: 1 [31600/42000 (75%)]\tLoss: 147.204391\n",
      "Train Epoch: 1 [32000/42000 (76%)]\tLoss: 147.940506\n",
      "Train Epoch: 1 [32400/42000 (77%)]\tLoss: 131.381699\n",
      "Train Epoch: 1 [32800/42000 (78%)]\tLoss: 127.768372\n",
      "Train Epoch: 1 [33200/42000 (79%)]\tLoss: 112.991455\n",
      "Train Epoch: 1 [33600/42000 (80%)]\tLoss: 94.955399\n",
      "Train Epoch: 1 [34000/42000 (81%)]\tLoss: 129.867096\n",
      "Train Epoch: 1 [34400/42000 (82%)]\tLoss: 105.178360\n",
      "Train Epoch: 1 [34800/42000 (83%)]\tLoss: 108.176254\n",
      "Train Epoch: 1 [35200/42000 (84%)]\tLoss: 118.924721\n",
      "Train Epoch: 1 [35600/42000 (85%)]\tLoss: 138.575409\n",
      "Train Epoch: 1 [36000/42000 (86%)]\tLoss: 108.325066\n",
      "Train Epoch: 1 [36400/42000 (87%)]\tLoss: 103.783310\n",
      "Train Epoch: 1 [36800/42000 (88%)]\tLoss: 109.294373\n",
      "Train Epoch: 1 [37200/42000 (89%)]\tLoss: 101.650246\n",
      "Train Epoch: 1 [37600/42000 (90%)]\tLoss: 106.753952\n",
      "Train Epoch: 1 [38000/42000 (90%)]\tLoss: 135.535828\n",
      "Train Epoch: 1 [38400/42000 (91%)]\tLoss: 110.629425\n",
      "Train Epoch: 1 [38800/42000 (92%)]\tLoss: 147.926880\n",
      "Train Epoch: 1 [39200/42000 (93%)]\tLoss: 107.714348\n",
      "Train Epoch: 1 [39600/42000 (94%)]\tLoss: 113.037880\n",
      "Train Epoch: 1 [40000/42000 (95%)]\tLoss: 95.148384\n",
      "Train Epoch: 1 [40400/42000 (96%)]\tLoss: 103.696777\n",
      "Train Epoch: 1 [40800/42000 (97%)]\tLoss: 137.594315\n",
      "Train Epoch: 1 [41200/42000 (98%)]\tLoss: 107.757599\n",
      "Train Epoch: 1 [41600/42000 (99%)]\tLoss: 102.715561\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-78e1d6d2b504>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m print('====> Epoch: {} Average loss: {:.4f}'.format(\n\u001b[0;32m---> 20\u001b[0;31m       epoch, train_loss / len(train_loader.dataset)))\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "#def train(epoch):\n",
    "epoch = 1\n",
    "model.train()\n",
    "train_loss = 0\n",
    "for batch_idx, (data, _) in enumerate(dataloader):\n",
    "    data = data.view(-1, 784) #.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    recon_batch, mu, logvar = model(data)\n",
    "    loss = loss_function(recon_batch, data, mu, logvar)\n",
    "    loss.backward()\n",
    "    train_loss += loss.item()\n",
    "    optimizer.step()\n",
    "    if batch_idx % 100 == 0:\n",
    "        print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "            epoch, batch_idx * len(data), len(mnist_dataset),\n",
    "            100. * batch_idx / len(dataloader),\n",
    "            loss.item() / len(data)))\n",
    "\n",
    "print('====> Epoch: {} Average loss: {:.4f}'.format(\n",
    "      epoch, train_loss / len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 28, 28])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(data[1][0].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f06b0834630>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f06b0929978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(model(data.reshape(-1, 784))[0].reshape(4,28,28)[2].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3544, -0.2594, -1.8047,  2.1147, -0.9204, -2.2100, -0.7898, -0.3405,\n",
       "         -0.8139, -0.3018],\n",
       "        [ 0.3035, -1.5446, -1.4792,  0.9002,  2.7652, -1.5214, -0.5923,  0.7390,\n",
       "          1.0623,  0.4475],\n",
       "        [ 0.9790, -1.4366, -0.5079,  0.4297, -2.2378,  0.2054,  0.0132, -1.9752,\n",
       "          2.2857,  0.1080],\n",
       "        [-1.4709,  0.9919,  0.9429,  0.4425,  0.8393, -0.1693, -0.2657,  0.4160,\n",
       "          1.2027, -0.8108]], grad_fn=<ThAddmmBackward>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.encode(data.reshape(-1, 784))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f7391873400>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f739192f710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(model.decode(torch.randn(10)).reshape(28,28).detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (data, _) in enumerate(test_loader):\n",
    "            data = data.to(device)\n",
    "            recon_batch, mu, logvar = model(data)\n",
    "            test_loss += loss_function(recon_batch, data, mu, logvar).item()\n",
    "            if i == 0:\n",
    "                n = min(data.size(0), 8)\n",
    "                comparison = torch.cat([data[:n],\n",
    "                                      recon_batch.view(args.batch_size, 1, 28, 28)[:n]])\n",
    "                save_image(comparison.cpu(),\n",
    "                         'results/reconstruction_' + str(epoch) + '.png', nrow=n)\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('====> Test set loss: {:.4f}'.format(test_loss))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        train(epoch)\n",
    "        test(epoch)\n",
    "        with torch.no_grad():\n",
    "            sample = torch.randn(64, 20).to(device)\n",
    "            sample = model.decode(sample).cpu()\n",
    "            save_image(sample.view(64, 1, 28, 28),\n",
    "'results/sample_' + str(epoch) + '.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
